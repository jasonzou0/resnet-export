{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ed1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import onnx\n",
    "\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4daffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_model(name):\n",
    "    #model = getattr(models, name)(pretrained=True)\n",
    "    if name == \"resnet18\":\n",
    "        default_weights = models.ResNet18_Weights.DEFAULT\n",
    "        model = models.resnet18(weights=default_weights)    \n",
    "        model.eval()\n",
    "        return model, default_weights\n",
    "\n",
    "model, weights = fetch_model(\"resnet18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4a3b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_jit(model, name=\"resnet18_torchscript.pt\"):\n",
    "    model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "    model_scripted.save(name) # Save\n",
    "\n",
    "    \n",
    "def save_to_pt(model, name=\"resnet18.pt\"):\n",
    "    torch.save(model.state_dict(), name)\n",
    "\n",
    "    \n",
    "def save_to_onnx(model, weights, name=\"resnet18.onnx\"):\n",
    "\n",
    "    img = read_image(\"/Users/zjy/Downloads/511px-Grace_Hopper.jpg\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Step 2: Initialize the inference transforms\n",
    "    preprocess = weights.transforms()\n",
    "\n",
    "    # Step 3: Apply inference preprocessing transforms\n",
    "    batch = preprocess(img).unsqueeze(0)\n",
    "\n",
    "    torch.onnx.export(model, batch, name, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2f100c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves all the tensors to disk in binary format with all float32s \n",
    "# serialized in little endianness order.\n",
    "\n",
    "import csv, re, uuid\n",
    "import os.path\n",
    "from itertools import chain\n",
    "from onnx import TensorProto\n",
    "\n",
    "def _is_valid_filename(filename):  # type: (Text) -> bool\n",
    "    \"\"\"Utility to check whether the provided filename is valid.\"\"\"\n",
    "    exp = re.compile(\"^[^<>:;,?\\\"*|/]+$\")\n",
    "    match = exp.match(filename)\n",
    "    if match:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def _sanitize_tensor_name(name):\n",
    "    return \"Tensor_\" + name.removeprefix(\"onnx::\")\n",
    "\n",
    "    \n",
    "def _get_initializer_tensors(onnx_model_proto):  # type: (ModelProto) -> Iterable[TensorProto]\n",
    "    \"\"\"Create an iterator of initializer tensors from ONNX model.\"\"\"\n",
    "    for initializer in onnx_model_proto.graph.initializer:\n",
    "        yield initializer\n",
    "\n",
    "\n",
    "def _get_attribute_tensors(onnx_model_proto):  # type: (ModelProto) -> Iterable[TensorProto]\n",
    "    \"\"\"Create an iterator of tensors from node attributes of an ONNX model.\"\"\"\n",
    "    for node in onnx_model_proto.graph.node:\n",
    "        for attribute in node.attribute:\n",
    "            if attribute.HasField(\"t\"):\n",
    "                yield _massage_tensor_name(node, attribute.t)\n",
    "            for tensor in attribute.tensors:\n",
    "                yield _massage_tensor_name(node, tensor)\n",
    "\n",
    "                \n",
    "def _get_all_tensors(onnx_model_proto):  # type: (ModelProto) -> Iterable[TensorProto]\n",
    "    \"\"\"Scan an ONNX model for all tensors and return as an iterator.\"\"\"\n",
    "    return chain(_get_initializer_tensors(onnx_model_proto),\n",
    "                 _get_attribute_tensors(onnx_model_proto))\n",
    "\n",
    "def _dims_to_str(dims):\n",
    "    return \",\".join(str(dim) for dim in dims)\n",
    "    \n",
    "    \n",
    "def dump_all_tensors_to_disk(onnx_model, location, metadata_file=\"tensor_metadata.csv\"):\n",
    "    assert os.path.isdir(location)\n",
    "    \n",
    "    metadata = []\n",
    "    for tensor in _get_all_tensors(onnx_model):\n",
    "        tensor_name = _sanitize_tensor_name(tensor.name)\n",
    "        assert _is_valid_filename(tensor_name)\n",
    "        tensor_attr = {}\n",
    "        tensor_attr[\"name\"] = tensor_name\n",
    "        tensor_attr[\"dims\"] = _dims_to_str(tensor.dims)\n",
    "        metadata.append(tensor_attr)\n",
    "        with open(os.path.join(location, \"tensors\", tensor_name), \"wb\") as f:\n",
    "            f.write(tensor.raw_data)\n",
    "    \n",
    "    # write tensor dimensions to disk\n",
    "    with open(os.path.join(location, \"metadata\", metadata_file), \"w\") as f:\n",
    "        dict_writer = csv.DictWriter(f, metadata[0].keys())\n",
    "        dict_writer.writeheader()\n",
    "        for row in metadata:\n",
    "            dict_writer.writerow(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08975f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collects and dumps metadata about the computation graph\n",
    "\n",
    "from onnx import AttributeProto\n",
    "\n",
    "def collapse_items(items):\n",
    "    \"\"\"collapse repeated items in a list into a single item\"\"\"\n",
    "    assert len(set(items)) == 1, items\n",
    "    return items[0]\n",
    "    \n",
    "\n",
    "def collect_conv_attributes(conv_node):\n",
    "    \"\"\"returns key attributes of a convolution node into a dict\"\"\"\n",
    "    assert conv_node.op_type == \"Conv\", conv_node    \n",
    "    attributes_dict = {}\n",
    "    for attr in conv_node.attribute:\n",
    "        if attr.name in (\"pads\", \"strides\"):\n",
    "            assert attr.type == AttributeProto.INTS\n",
    "            attributes_dict[attr.name] = collapse_items(attr.ints)\n",
    "    return attributes_dict\n",
    "    \n",
    "    \n",
    "def collect_initializer_tensor_names(node):\n",
    "    \"\"\"returns tensor names of a convolution or FC/Gemm node into a dict\"\"\"\n",
    "    if node.op_type == \"Conv\":\n",
    "        _, t1, t2 = node.input\n",
    "        assert t1.startswith(\"onnx::\") and t2.startswith(\"onnx::\"), node.input\n",
    "    elif node.op_type == \"Gemm\":\n",
    "        _, t1, t2 = node.input\n",
    "        assert t1.startswith(\"fc\") and t2.startswith(\"fc\"), node.input    \n",
    "    else:\n",
    "        return {}\n",
    "    return {\"W\": _sanitize_tensor_name(t1), \"B\": _sanitize_tensor_name(t2)}\n",
    "\n",
    "\n",
    "def collect_input_tensors(node):\n",
    "    \"\"\"Collect input tensors minus the initializer of each operator node. Returns a list of tensor names.\"\"\"\n",
    "    input_tensors = []\n",
    "    if node.op_type in (\"Conv\", \"Gemm\"):\n",
    "        input_tensors.append(_sanitize_tensor_name(node.input[0]))\n",
    "    else:\n",
    "        input_tensors = [_sanitize_tensor_name(in_tensor) for in_tensor in node.input]\n",
    "    return input_tensors\n",
    "\n",
    "\n",
    "def collect_graph_info(onnx_model_proto):\n",
    "    \"\"\"collect onnx graph info into a list of node info, where node info is a dict of key attributes of a node\"\"\"\n",
    "    node_info = []\n",
    "    for node in onnx_model_proto.graph.node:\n",
    "        node_attributes = {}\n",
    "        node_attributes[\"name\"] = node.name\n",
    "        node_attributes[\"type\"] = node.op_type\n",
    "        node_attributes[\"input\"] = \",\".join(collect_input_tensors(node))\n",
    "        node_attributes[\"output\"] = _sanitize_tensor_name(collapse_items(node.output))\n",
    "\n",
    "        #print(f\"Node name {node.name} with input {node.input} and output {node.output}\")\n",
    "        if node.op_type == \"Conv\":\n",
    "            node_attributes.update(collect_conv_attributes(node))\n",
    "        node_attributes.update(collect_initializer_tensor_names(node))\n",
    "        node_info.append(node_attributes)\n",
    "    return node_info\n",
    "\n",
    "\n",
    "def write_graph_info(graph_info, model_dump_location, metadata_name=\"graph_metadata.csv\"):\n",
    "    with open(os.path.join(model_dump_location, \"metadata\", metadata_name), \"w\") as f:\n",
    "        assert graph_info[0][\"type\"] == \"Conv\"\n",
    "        dict_writer = csv.DictWriter(f, graph_info[0].keys())\n",
    "        dict_writer.writeheader()\n",
    "        for row in graph_info:\n",
    "            dict_writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a2587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect_graph_info(onnx_model_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb995824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.txt    \u001b[34mmetadata\u001b[m\u001b[m      \u001b[34moriginal_onnx\u001b[m\u001b[m \u001b[34mtensors\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "MODEL_DUMP_DIR = \"model_dump/resnet18\"\n",
    "onnx_model_proto = onnx.load(os.path.join(MODEL_DUMP_DIR, \"original_onnx/production_resnet18.onnx\"))\n",
    "dump_all_tensors_to_disk(onnx_model_proto, MODEL_DUMP_DIR)\n",
    "graph_info = collect_graph_info(onnx_model_proto)\n",
    "write_graph_info(graph_info, MODEL_DUMP_DIR)\n",
    "\n",
    "!{ls model_dump/resnet18}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
